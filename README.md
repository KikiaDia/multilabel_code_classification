# Codeforces Multilabel Classification 

**Auteur :** Kikia Dia  
**Illuin Technology Challenge :** Data Science

---
### Structure du projet
```
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ EDA.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ Machine_learning_models.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ transformers.ipynb
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ training.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ code_features.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ model.joblib
‚îÇ   ‚îî‚îÄ‚îÄ model_tfidf.joblib
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```
## Contexte

Codeforces est une plateforme de programmation comp√©titive regroupant des milliers de probl√®mes d'algorithmique, chacun annot√© par plusieurs **tags** repr√©sentant les notions algorithmiques mobilis√©es (`math`, `graphs`, `strings`, etc.).

Ce projet s'appuie sur un **sous-ensemble du dataset xCodeEval** compos√© de **4 982 probl√®mes distincts**, incluant :
- `prob_desc_description` : descriptions textuelles compl√®tes ,
- `prob_desc_input_spec`, `prob_desc_output_spec` : sp√©cifications d'entr√©e/sortie,
- `prob_desc_notes` : notes √©ventuelles,
- `source_code` : solutions valid√©es en Python,
- `tags` : annotations multi-labels.

## Objectif

Construire un **algorithme de classification multi-label** capable de pr√©dire automatiquement les tags associ√©s √† un probl√®me d'algorithmique.

L'√©tude se concentre sur les **8 tags suivants** :
```python
['math', 'graphs', 'strings', 'number theory',
 'trees', 'geometry', 'games', 'probabilities']
```
Apr√®s filtrage pour ne garder que les exemples correspondant √† ces tags, le dataset final contient **2 678 probl√®mes**.

Nombre d'exemples par tag (8 cibles) :
math: 1409,
graphs: 542,
strings: 422
number theory: 350,
trees: 324,
geometry: 166,
games: 105,
probabilities: 92

![tag distribution](images/tags_distribution.png)

### Dataset preview

| prob_desc_description | prob_desc_input_spec | prob_desc_output_spec | prob_desc_notes | source_code | tags |
|--------------------|------------------|-------------------|---------------|-------------------|------|
| Once upon a time, Oolimry saw a suffix array... | The first line contain 2 integers $$$n$$$ and ... | Print how many strings produce such a suffix array... | NoteIn the first test case, "abb" is the only ... | import sys\ninput = sys.stdin.readline\n... | [math] |
| You are given an array of n elements, you must... | The first line contains integer n (1‚Äâ‚â§‚Äân‚Äâ‚â§‚Äâ100...) | Print integer k on the first line ‚Äî the least ... |  | def gcd(a,b):\n if b==0:return a\n return ... | [number theory, math] |

### Exploratory Data Analysis (EDA)
- Longueur des descriptions, Distribution des tags, Co-occurrence des labels, Wordclouds par tag, Analyse des patterns algorithmiques dans le code
#### Text Preprocessing

- **Champs concaten√©s  pour la description :** `prob_desc_description`,`prob_desc_input_spec`,`prob_desc_output_spec`, `prob_desc_notes`

- **Nettoyage du texte :** Tokenisation (NLTK), Normalisation, Suppression de stopwords, stemming

- Before preprocessing

![Wordcloud avant preprocessing](images/before_preprocessing.png)

- After preprocessing

![Wordcloud apr√®s preprocessing](images/after_preprocessing.png)

### Repr√©sentation des labels :
- one-hot-encoding avec `MultiLabelBinarizer`

### Data Splitting

Le dataset a √©t√© divis√© en deux ensembles :
- **Train :** 80% des donn√©es (2 142 probl√®mes)
- **Validation :** 20% des donn√©es (536 probl√®mes)

### Text Vectorisation
- **TF-IDF:**  `max_features = 5000`, `ngram_range = (1, 2)`

## Mod√©lisation

- **Strat√©gies multi-label :** `One-vs-Rest`, `MultiOutputClassifier`, `Classifier Chains`
- **Classificateurs test√©s :** `Logistic Regression`,`Random Forest`,`LinearSVC`
- **M√©triques d'√©valuation :** `Micro F1-score`, `Macro F1-score`, `Hamming Loss`, `Subset Accuracy`, `Precision / Recall par tag`

- **Best Model**: `OneVsRest + LinearSVC (class_weight="balanced")`, Optimisation via `GridSearchCV` , best_params = {'estimator__C': 0.1,'estimator__loss': 'squared_hinge''estimator__max_iter': 1000, 'estimator__tol': 0.0001}

### Approches test√©es :

- description

- description + features extraits du code Python 

- gestion du d√©s√©quilibre avec MLSMOTE (Multi-Label SMOTE)

## Evaluation

### Comparaison des approches (tri√©es par Macro F1)

| Approach | F1 Micro | F1 Macro | Hamming Loss | Subset Accuracy |
|----------|----------|----------|--------------|----------------|
| **Descriptions + code features** | **0.7428** | **0.6969** | **0.0898** | **0.4925** |
| Descriptions only | 0.7139 | 0.6663 | 0.0989 | 0.4459 |
| Resampled (SMOTE) | 0.6978 | 0.6670 | 0.1056 | 0.4216 |

**üèÜ Meilleur approche :** Descriptions + code features

### Matrices de confusion

![Matrices de confusion](images/matrices_confusion.png)

#### f1_score par tag

![f1_score_per_tag](images/f1_score.png)

**best predicted tags** : `math`, `strings`, `games`, `trees`

Pour plus de d√©tails, consultez le notebook d'entra√Ænement `notebooks/Machine_learning_models.ipynb`

---

## Utilisation du CLI

```bash
# training and evaluation on description only

python src/main.py train --data data/train --output models/model.joblib

python src/main.py evaluate --model models/model.joblib --data data/test  

# prediction unitaire 
python src/main.py predict --model models/model.joblib --text """Numbers...."""
```
```bash
# training and evaluation on description + code features 

python src/main.py train --data data/train --output models/model_hybrid.joblib --hybrid

python src/main.py evaluate --model models/model_hybrid.joblib --data data/test --hybrid --results-path results/predictions_test_hybrid.csv

# prediction unitaire 
python src/main.py predict --model models/model_hybrid.joblib --text "Numbers.." --code """ import..."""
```

---

## Autres Pistes d'am√©lioration

### Mod√®les Transformers

Des exp√©rimentations ont √©t√© men√©es avec des mod√®les Transformers pr√©-entra√Æn√©s, notamment :
```python
model_names = [
    "microsoft/codebert-base",
    "microsoft/graphcodebert-base",
    "microsoft/unixcoder-base",
    "bert-base-uncased"
]
```

Ces mod√®les, sp√©cialement con√ßus pour la compr√©hension du code (CodeBERT, GraphCodeBERT, UniXcoder) ou du texte naturel (BERT), pourraient potentiellement am√©liorer les performances en capturant des repr√©sentations s√©mantiques plus riches.

**Comparaison des mod√®les Transformers (derni√®re √©poque)** 

| Mod√®le                     | F1 Micro | F1 Macro | Hamming Loss | Train Loss | Val Loss | Runtime (s) |
|----------------------------|----------|----------|--------------|------------|----------|------------|
| microsoft/graphcodebert-base | 0.7865  | 0.7394   | 0.0665       | 0.0879     | 0.2050   | 17.41      |
| microsoft/unixcoder-base    | 0.7609  | 0.7276   | 0.0742       | 0.0808     | 0.2200   | 17.28      |
| microsoft/codebert-base     | 0.7618  | 0.6996   | 0.0732       | 0.104      | 0.2101   | 17.16      |
| bert-base-uncased           | 0.7613  | 0.6793   | 0.0730       | 0.1217     | 0.2135   | 17.78      |

remarque : risque d'overfitting, mod√®les complexes

Pour plus de d√©tails sur les exp√©rimentations avec les Transformers, consultez le notebook : `notebooks/transformers.ipynb`

