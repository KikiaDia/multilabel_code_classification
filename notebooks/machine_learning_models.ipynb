{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYbRZ14zdryV"
   },
   "source": [
    "<h1>Mod√©lisation : Pr√©diction des tags algorithmiques</h1>\n",
    "<h2>Approches Machine Learning </h2>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2> Objectif de cette section</h2>\n",
    "\n",
    "<p>\n",
    "L‚Äôobjectif de cette section est de concevoir, entra√Æner et comparer plusieurs mod√®les\n",
    "pour la t√¢che de <strong>classification multi-labels</strong> des exercices d‚Äôalgorithmique.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Nous explorons successivement :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>des mod√®les classiques de Machine Learning bas√©s sur le texte,</li>\n",
    "  <li>des approches hybrides combinant texte et features issues du code source,</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvwFH2oEeNAe"
   },
   "source": [
    "<h2>Sommaire</h2>\n",
    "\n",
    "<ol>\n",
    "  <li><a href=\"#1-preparation-des-donnees\">Pr√©paration des donn√©es</a></li>\n",
    "  <li><a href=\"#2-One-hot-encoding-et-data-splitting\">One-hot-encoding et data splitting</a></li>\n",
    "  <li><a href=\"#3-vectorisation-tfidf\">Vectorisation TF-IDF</a></li>\n",
    "  <li><a href=\"#4-modeles-machine-learning\">Mod√®les Machine Learning classiques</a></li>\n",
    "  <li><a href=\"#5-optimisation-des-hyperparametres\">Optimisation des hyperparam√®tres</a></li>\n",
    "  <li><a href=\"#6-approche-hybride-texte-code\">Approche hybride : texte + code source</a></li>\n",
    "  <li><a href=\"#7-comparaison-des-performances\">Comparaison des performances</a></li>\n",
    "</ol>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjq6YJp2qEpx"
   },
   "source": [
    "### Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-LC6Sz_cjGw",
    "outputId": "79da6345-2269-4471-d4f2-311de4a8480f"
   },
   "outputs": [],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWUpSPmrkr1n"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss, accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from google.colab import drive\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import contractions\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P45dhqGr5Ko-"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Fixer la seed globale\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxc-T2m7ek6k"
   },
   "source": [
    "### 1. Pr√©paration des donn√©es\n",
    "\n",
    "<p>\n",
    "Les donn√©es sont charg√©es √† partir de fichiers JSON.\n",
    "Chaque exercice est associ√© √† :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>une description textuelle nettoy√©e,</li>\n",
    "  <li>le code source en Python,</li>\n",
    "  <li>une liste de tags (multi-label).</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RztBHHkJp4-U",
    "outputId": "ecbc9b45-fdd0-47e4-dae0-8e37a484cfca"
   },
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HU6WTTWYb0cs",
    "outputId": "781da29d-2131-4c09-bf38-dd4b842864e7"
   },
   "outputs": [],
   "source": [
    "# Chemins (√† adapter si besoin)\n",
    "ZIP_PATH = \"/content/drive/MyDrive/code_classification_dataset.zip\"\n",
    "DATASET_DIR = \"/content/data\"\n",
    "\n",
    "# Cr√©er le dossier de destination s'il n'existe pas\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "# Extraire le zip\n",
    "with zipfile.ZipFile(ZIP_PATH, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(DATASET_DIR)\n",
    "\n",
    "print(\"Fichiers extraits :\", len(os.listdir(\"/content/data/code_classification_dataset\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfVP_Iowq-iL"
   },
   "outputs": [],
   "source": [
    "TEXT_FIELDS = [\n",
    "    \"prob_desc_description\",\n",
    "    \"prob_desc_input_spec\",\n",
    "    \"prob_desc_output_spec\",\n",
    "    \"prob_desc_notes\",\n",
    "    \"source_code\",\n",
    "    \"tags\",\n",
    "]\n",
    "\n",
    "def load_dataset(dataset_dir):\n",
    "    records = []\n",
    "    json_files = glob(os.path.join(dataset_dir, \"*.json\"))\n",
    "    print(f\"{len(json_files)} fichiers JSON trouv√©s\")\n",
    "\n",
    "    for path in json_files:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Cr√©er un nouveau dictionnaire pour chaque fichier JSON\n",
    "        record = {}\n",
    "        for field in TEXT_FIELDS:\n",
    "            record[field] = data.get(field, \"\") or \"\"\n",
    "\n",
    "        # S'assurer que 'tags' est une liste\n",
    "        if not isinstance(record[\"tags\"], list):\n",
    "            record[\"tags\"] = []\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Nettoyage suppl√©mentaire\n",
    "    for field in TEXT_FIELDS:\n",
    "        df[field] = df[field].fillna(\"\")\n",
    "\n",
    "    # Forcer l'ordre des colonnes\n",
    "    df = df[TEXT_FIELDS]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy0__wFPWg2e",
    "outputId": "176b6b82-9b8a-42bb-9ca8-f54dd6396326"
   },
   "outputs": [],
   "source": [
    "df = load_dataset(\"/content/data/code_classification_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "BTdVCN5tgE6H",
    "outputId": "58195bac-7c53-4108-c6dc-c42c1465aba6"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaKTaS9Slnmy"
   },
   "outputs": [],
   "source": [
    "TARGET_TAGS = [\n",
    "    'math', 'graphs', 'strings', 'number theory',\n",
    "    'trees', 'geometry', 'games', 'probabilities'\n",
    "]\n",
    "\n",
    "def filter_target_tags(tags):\n",
    "    return [t for t in tags if t in TARGET_TAGS]\n",
    "\n",
    "df[\"tags\"] = df[\"tags\"].apply(filter_target_tags)\n",
    "\n",
    "df = df[df[\"tags\"].map(len) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "PojZoSbRgiz4",
    "outputId": "381f4f13-41c0-4732-ba5c-bd1dbf0d1ed3"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "h3rz2wC9jdy1",
    "outputId": "1eaac8ea-8276-4f26-b4c5-2c82cdf92062"
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXoGLY0elFbW"
   },
   "outputs": [],
   "source": [
    "# Colonnes √† concat√©ner\n",
    "cols_to_concat = [\n",
    "    \"prob_desc_description\",\n",
    "    \"prob_desc_input_spec\",\n",
    "    \"prob_desc_output_spec\",\n",
    "    \"prob_desc_notes\"\n",
    "]\n",
    "\n",
    "# Cr√©er une nouvelle colonne 'description' en concat√©nant les colonnes avec un espace\n",
    "df['description'] = df[cols_to_concat].agg(' '.join, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "V0Nmcl6wtBkY",
    "outputId": "e0ca2eca-4549-46be-f9c9-da44c65cfdfe"
   },
   "outputs": [],
   "source": [
    "df[\"description\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "lBrjqpsmE3Kx",
    "outputId": "d80cc845-4ff0-4a61-a07b-604788768f78"
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92e9e795",
    "outputId": "c9155ebb-b667-49db-9180-ba67ce4b3a22"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "class DataProcessor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "        # self.lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        self.stemmer = nltk.stem.SnowballStemmer(\"english\")\n",
    "\n",
    "    def __call__(self, text: str) -> str:\n",
    "\n",
    "        text = text.lower() # Lowercase\n",
    "        text = text.replace('-', ' ') # Replace hyphens with spaces\n",
    "        text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text) # Remove special characters\n",
    "        text = re.sub(r\"\\s+\", \" \", text) # Remove extra whitespaces\n",
    "        text = re.sub(r\"\\d+\", \" \", text) # Remove digits\n",
    "        text = contractions.fix(text) # Expand contractions, for example don't -> do not\n",
    "\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in self.stopwords]\n",
    "        # tokens = [self.lemmatizer.lemmatize(word) for word in tokens]\n",
    "        tokens = [self.stemmer.stem(word) for word in tokens]\n",
    "\n",
    "        return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90SfZ0I2gH4u"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d755dadd12ca42e49cc3da24f09cb9e2",
      "27dad44bc66b4b31afa9545098c95e36",
      "6a966cf1d88e4a7d9298bc1e1cbe9e2a",
      "3ac3432d6c2143318ad7683c27b4897e",
      "d9b1caa8b14b4f6db1d602525082aadd",
      "7b88b7a2b7ee4c729639afc032787e26",
      "6be54fe376784722a6a61384caf6d839",
      "fdae4800015a42e9a8342aa80c31ec32",
      "0f312db1770241a198290debe179d09d",
      "9123cdba051645a8932450bcf2731624",
      "f7686fca67c748ea9613bff24cde019b"
     ]
    },
    "id": "d37a71c7",
    "outputId": "9f76b6f8-0bbf-424d-d543-367103c1a897"
   },
   "outputs": [],
   "source": [
    "processor = DataProcessor()\n",
    "df['description_clean'] = df['description'].progress_apply(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "7jhABgDjdqTx",
    "outputId": "977a0625-056d-449a-dc9e-36bada45b657"
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "7Z9DzeBagxmJ",
    "outputId": "6ccddbde-4767-47b4-db58-5094beaf601c"
   },
   "outputs": [],
   "source": [
    "df.iloc[0][\"description_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obk5ase4-dOk"
   },
   "outputs": [],
   "source": [
    "# df = pd.concat(\n",
    "#     [\n",
    "#         df[[\"description_clean\", \"source_code\"]].reset_index(drop=True),\n",
    "#         pd.DataFrame(\n",
    "#             y,\n",
    "#             columns=mlb.classes_\n",
    "#         )\n",
    "#     ],\n",
    "#     axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPq_5p-ZBPx7"
   },
   "source": [
    "### 2. One-hot-encoding et data splitting\n",
    "<p>\n",
    "Les tags sont binaris√©s √† l‚Äôaide d‚Äôun <code>MultiLabelBinarizer</code>,\n",
    "et les donn√©es sont s√©par√©es en ensembles d‚Äôentra√Ænement et de validation (80/20).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kj3eGqmmGwhg"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df[\"tags\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpX5jH_nGwhh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"description_clean\"].tolist(),\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PYWKAgafEPv"
   },
   "source": [
    "### 3. *Vectorisation* TF-IDF\n",
    "\n",
    "<p>\n",
    "Le texte des descriptions est vectoris√© √† l‚Äôaide de la m√©thode <strong>TF-IDF</strong>,\n",
    "avec les param√®tres suivants :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>maximum de 5000 features,</li>\n",
    "  <li>n-grammes de taille 1 et 2.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Cette repr√©sentation permet de capturer √† la fois le vocabulaire sp√©cifique\n",
    "et certaines expressions caract√©ristiques des probl√®mes algorithmiques.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgjvnBEjlY9X"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. TF-IDF\n",
    "# -----------------------------\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwIk3xO3fTjE"
   },
   "source": [
    "### 4. Mod√®les Machine Learning classiques\n",
    "\n",
    "<p>\n",
    "Plusieurs classificateurs de base sont √©valu√©s, chacun int√©gr√© dans diff√©rentes\n",
    "strat√©gies multi-label :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>One-vs-Rest (OvR)</strong></li>\n",
    "  <li><strong>MultiOutputClassifier</strong></li>\n",
    "  <li><strong>Classifier Chains</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Les classificateurs de base test√©s sont :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>Logistic Regression</li>\n",
    "  <li>Random Forest</li>\n",
    "  <li>Support Vector Machines (SVC, LinearSVC)</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Les performances sont √©valu√©es √† l‚Äôaide de m√©triques adapt√©es au multi-label,\n",
    "notamment le <strong>Micro F1-score</strong>, le <strong>Macro F1-score</strong>, le <strong>hamming_loss</strong> et le <strong>subset_accuracy</strong>.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7dhQNh5lrI-",
    "outputId": "eedb13b2-ea93-4f30-ba00-a465f84434fc"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. D√©finir classificateurs de base\n",
    "# -----------------------------\n",
    "\n",
    "base_classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"SVC\": SVC(\n",
    "        kernel=\"linear\",\n",
    "        probability=True,\n",
    "        class_weight=\"balanced\"\n",
    "    ),\n",
    "    \"LinearSVC\": LinearSVC(\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 3. D√©finir mod√®les multi-label\n",
    "# -----------------------------\n",
    "models = {}\n",
    "for name, clf in base_classifiers.items():\n",
    "    models[f\"OVR_{name}\"] = OneVsRestClassifier(clf)\n",
    "    models[f\"MultiOutput_{name}\"] = MultiOutputClassifier(clf)\n",
    "    models[f\"Chain_{name}\"] = ClassifierChain(clf, order='random', random_state=42)\n",
    "print(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wakdb-6oWrUw"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Fonction pour entra√Æner et pr√©dire\n",
    "# -----------------------------\n",
    "def train_and_predict(model, X_train, y_train, X_val):\n",
    "    \"\"\"\n",
    "    Entra√Æne le mod√®le et retourne les pr√©dictions sur X_val\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJJ5lcc0W3_-"
   },
   "outputs": [],
   "source": [
    "def get_target_names(y_true, mlb=None):\n",
    "    \"\"\"\n",
    "    Retourne les noms des labels pour le classification_report.\n",
    "\n",
    "    - Si y_true est un DataFrame -> colonnes\n",
    "    - Si y_true est un ndarray et mlb fourni -> mlb.classes_\n",
    "    - Sinon -> tag_0, tag_1, ...\n",
    "    \"\"\"\n",
    "    if hasattr(y_true, \"columns\"):\n",
    "        return y_true.columns.tolist()\n",
    "    elif isinstance(y_true, (np.ndarray)) and mlb is not None:\n",
    "        return mlb.classes_.tolist()\n",
    "    elif isinstance(y_true, (np.ndarray)):\n",
    "        return [f\"tag_{i}\" for i in range(y_true.shape[1])]\n",
    "    else:\n",
    "        raise ValueError(\"Impossible de d√©terminer les noms des labels. Fournissez y_true ou mlb correctement.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ehQD1gqXL8G"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Fonction pour calculer et afficher les m√©triques\n",
    "# -----------------------------\n",
    "def evaluate_multilabel(y_true, y_pred, mlb=None):\n",
    "    \"\"\"\n",
    "    Calcule et affiche les m√©triques multi-label et le classification report\n",
    "    \"\"\"\n",
    "    f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    subset_acc = accuracy_score(y_true, y_pred)\n",
    "    prec_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    rec_micro = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "    print(f\"\\n‚úÖ Micro F1: {f1_micro:.3f}, Macro F1: {f1_macro:.3f}\")\n",
    "    print(f\"Hamming Loss: {hamming:.3f}, Subset Accuracy: {subset_acc:.3f}\")\n",
    "    print(f\"Micro Precision: {prec_micro:.3f}, Micro Recall: {rec_micro:.3f}\")\n",
    "\n",
    "    # R√©cup√©rer les noms des labels\n",
    "    target_names = get_target_names(y_true, mlb)\n",
    "\n",
    "    print(\"\\n - Classification report par tag :\")\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names, zero_division=0))\n",
    "\n",
    "    return {\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"hamming_loss\": hamming,\n",
    "        \"subset_accuracy\": subset_acc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QqSFZj3Xu-U"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Fonction pour sauvegarder le mod√®le uniquement\n",
    "# -----------------------------\n",
    "def save_model(model, save_dir, model_name=\"best_model.joblib\"):\n",
    "    \"\"\"\n",
    "    Sauvegarde le mod√®le dans le r√©pertoire `save_dir` avec le nom `model_name`.\n",
    "    Cr√©e le dossier si n√©cessaire.\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_path = save_dir / model_name\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "    print(f\"‚úÖ Mod√®le sauvegard√© ici : {model_path}\")\n",
    "    return model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5T5v_vLXSYn",
    "outputId": "12ee2caf-b3e7-49df-a08a-5a0a8bb97635"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Entra√Æner et √©valuer tous les mod√®les\n",
    "# -----------------------------\n",
    "results_1 = []\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Entra√Æner et pr√©dire\n",
    "    print(f\"\\nüöÄ Training {model_name}...\")\n",
    "    y_pred = train_and_predict(model, X_train_tfidf, y_train, X_val_tfidf)\n",
    "\n",
    "    # √âvaluer le mod√®le et r√©cup√©rer les m√©triques\n",
    "    metrics = evaluate_multilabel(y_val, y_pred, mlb=mlb)\n",
    "\n",
    "    # Ajouter les m√©triques au tableau des r√©sultats\n",
    "    results_1.append({\n",
    "        \"model\": model_name,\n",
    "        \"f1_micro\": metrics[\"f1_micro\"],\n",
    "        \"f1_macro\": metrics[\"f1_macro\"],\n",
    "        \"hamming_loss\": metrics[\"hamming_loss\"],\n",
    "        \"subset_accuracy\": metrics[\"subset_accuracy\"]\n",
    "    })\n",
    "\n",
    "    # Stocker le mod√®le entra√Æn√©\n",
    "    trained_models[model_name] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "1POkPps_bAux",
    "outputId": "a3bfcd80-8b01-4a50-bb88-c1681b4ceedf"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5. R√©sultats tri√©s par Macro F1\n",
    "# -----------------------------\n",
    "results_df_1 = pd.DataFrame(results_1).sort_values(by='f1_macro', ascending=False)\n",
    "print(\"\\n=== R√©sultats finaux tri√©s par Macro F1 ===\")\n",
    "results_df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MezHvXb01mS5",
    "outputId": "ec48a3a8-0094-4217-8a3d-b63dbd0a7f91"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Identifier le meilleur mod√®le (Macro F1)\n",
    "# -----------------------------\n",
    "best_model_info_1 = results_df_1.iloc[0]           # premi√®re ligne = meilleur mod√®le\n",
    "best_model_name_1 = best_model_info_1[\"model\"]    # nom du mod√®le\n",
    "best_model_1 = models[best_model_name_1]          # r√©cup√©rer l'objet mod√®le\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le : {best_model_name_1}\")\n",
    "print(f\"Macro F1 : {best_model_info_1['f1_macro']:.3f}, Micro F1 : {best_model_info_1['f1_micro']:.3f}\")\n",
    "\n",
    "print(\"Hyperparam√®tres du meilleur mod√®le :\")\n",
    "best_params_1 = best_model_1.get_params()\n",
    "print(best_params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guKX_qITMGRq",
    "outputId": "fc0cd6f5-a871-4be2-d01f-90a783d19f55"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Sauvegarder le mod√®le\n",
    "# -----------------------------\n",
    "save_dir_1 = Path(\"/content/drive/MyDrive/codeforces_classifier/best_classifier\")\n",
    "save_model(best_model_1, save_dir_1,best_model_name_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13BYiGqIfg6n"
   },
   "source": [
    "### 5. Optimisation des hyperparam√®tres\n",
    "\n",
    "<p>\n",
    "Une recherche par grille (<code>GridSearchCV</code>) est r√©alis√©e\n",
    "sur le mod√®le le plus performant afin d‚Äôoptimiser les hyperparam√®tres,\n",
    "en utilisant le <strong>Micro F1-score</strong> comme m√©trique principale.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Cette √©tape permet d‚Äôam√©liorer la g√©n√©ralisation du mod√®le\n",
    "tout en prenant en compte le d√©s√©quilibre entre les classes.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C39P2ecdLEgb",
    "outputId": "033a0831-98fa-4fe3-8e46-310f81f9254e"
   },
   "outputs": [],
   "source": [
    "base_model = OneVsRestClassifier(\n",
    "    LinearSVC(class_weight=\"balanced\", random_state=42)\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"estimator__C\": [0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "    \"estimator__loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    \"estimator__max_iter\": [1000, 3000],\n",
    "    \"estimator__tol\": [1e-4, 1e-3]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_micro\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "print(\"‚úÖ Meilleurs param√®tres :\")\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)\n",
    "\n",
    "print(\"\\n‚úÖ Meilleur score CV (F1 micro) :\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UelYVrrcLza_",
    "outputId": "8db585d1-fbe7-4ca5-840a-d468bf363a12"
   },
   "outputs": [],
   "source": [
    "best_model_2 = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model_2.predict(X_val_tfidf)\n",
    "\n",
    "# √âvaluer le mod√®le et r√©cup√©rer les m√©triques\n",
    "metrics_2 = evaluate_multilabel(y_val, y_pred, mlb=mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-O1JzwXZH70R",
    "outputId": "b1c3168f-8399-4899-e42b-208bec1af4a6"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Sauvegarder le mod√®le\n",
    "# -----------------------------\n",
    "save_dir_2 = Path(\"/content/drive/MyDrive/codeforces_classifier/grid_search\")\n",
    "\n",
    "save_model(best_model_2, save_dir_2, model_name=\"best_grid_search_ovr_linear_svc.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dK4KhU0ZkgQR",
    "outputId": "00b117bb-342d-4e1b-961e-32d0cfeb8d29"
   },
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gA2TJY6di33"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Fonction principale : pipeline OVR_LinearSVC\n",
    "# -----------------------------\n",
    "def run_ovr_linear_svc_pipeline(X_train, y_train, X_val, y_val, best_params, save_dir, model_name=\"best_ovr_linear_svc.joblib\", mlb=None):\n",
    "    \"\"\"\n",
    "    Entra√Æne un OneVsRest LinearSVC avec les meilleurs hyperparam√®tres,\n",
    "    √©value les m√©triques multi-label et sauvegarde le mod√®le.\n",
    "\n",
    "    Arguments :\n",
    "        X_train, y_train : donn√©es d'entra√Ænement\n",
    "        X_val, y_val : donn√©es de validation\n",
    "        best_params : dict des meilleurs hyperparam√®tres pour LinearSVC\n",
    "        save_dir : r√©pertoire pour sauvegarder le mod√®le\n",
    "        model_name : nom du fichier sauvegard√©\n",
    "        mlb : MultiLabelBinarizer, optionnel si y_val est ndarray\n",
    "\n",
    "    Retourne :\n",
    "        best_model : mod√®le entra√Æn√©\n",
    "        metrics : dict des m√©triques\n",
    "    \"\"\"\n",
    "    # Si les cl√©s contiennent 'estimator__', on les retire\n",
    "    clean_params = {k.replace(\"estimator__\", \"\"): v for k, v in best_params.items()}\n",
    "\n",
    "    # Cr√©er le mod√®le\n",
    "    best_model = OneVsRestClassifier(\n",
    "        LinearSVC(class_weight=\"balanced\", **clean_params)\n",
    "    )\n",
    "\n",
    "    # Entra√Æner et pr√©dire\n",
    "    print(f\"\\nüöÄ Training OVR_LinearSVC with params: {best_params}\")\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    # √âvaluer\n",
    "    metrics = evaluate_multilabel(y_val, y_pred, mlb)\n",
    "\n",
    "    # Sauvegarder le mod√®le\n",
    "    save_dir = Path(save_dir)\n",
    "    save_model(best_model,save_dir, model_name)\n",
    "\n",
    "    return best_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RR8URz_Bfo5K"
   },
   "source": [
    "### 6. Approche hybride : texte + code source\n",
    "\n",
    "<p>\n",
    "En compl√©ment du texte, des features binaires sont extraites\n",
    "directement du code source afin de capturer des indices algorithmiques explicites :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>pr√©sence de DFS/BFS,</li>\n",
    "  <li>utilisation du modulo ou de la r√©cursion,</li>\n",
    "  <li>structures de graphes ou d‚Äôarbres,</li>\n",
    "  <li>√©l√©ments li√©s aux probabilit√©s ou aux jeux.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Les features issues du code sont concat√©n√©es aux vecteurs TF-IDF\n",
    "afin de former une repr√©sentation hybride plus expressive.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHbLJ52szsAc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OW146fvnvkM2"
   },
   "outputs": [],
   "source": [
    "# def extract_code_features(code):\n",
    "#     \"\"\"\n",
    "#     Extraire des features pertinentes pour pr√©dire les tags algorithmique.\n",
    "#     \"\"\"\n",
    "#     features = {}\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # 1Ô∏è‚É£ Structures math√©matiques\n",
    "#     # -----------------------------\n",
    "#     features['has_mod'] = int('%' in code)                    # modulo\n",
    "#     features['has_pow'] = int('**' in code or 'pow(' in code) # exponentiation\n",
    "#     features['has_factorial'] = int('fact' in code)           # factorielle\n",
    "#     features['has_comb'] = int('comb' in code)                # combinaisons\n",
    "#     features['has_math_import'] = int('import math' in code)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Graphes / parcours\n",
    "#     # -----------------------------\n",
    "#     features['has_dfs'] = int('dfs' in code.lower())          # DFS\n",
    "#     features['has_bfs'] = int('bfs' in code.lower())          # BFS\n",
    "#     features['has_edges'] = int('edges' in code.lower())\n",
    "#     features['has_adj'] = int('adj' in code.lower())          # adjacency\n",
    "#     features['has_graph_list'] = int('graph' in code.lower())\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # R√©cursion / structures arborescentes\n",
    "#     # -----------------------------\n",
    "#     features['has_recursion'] = int('def' in code and code.count('def') > 1)\n",
    "#     features['has_tree'] = int('tree' in code.lower())\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Cha√Ænes et manipulation de strings\n",
    "#     # -----------------------------\n",
    "#     features['has_string'] = int('str(' in code or '\"' in code or \"'\" in code)\n",
    "#     # features['has_split'] = int('.split(' in code)\n",
    "#     features['has_join'] = int('.join(' in code)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Jeux / probabilit√©s\n",
    "#     # -----------------------------\n",
    "#     features['has_random'] = int('random' in code)           # tirage al√©atoire\n",
    "#     features['has_probability'] = int('prob' in code.lower() or 'chance' in code.lower())\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Boucles / it√©rations\n",
    "#     # -----------------------------\n",
    "#     # features['has_for'] = int('for ' in code)\n",
    "#     features['has_while'] = int('while ' in code)\n",
    "#     # features['has_nested_loops'] = int(code.count('for ') + code.count('while ') > 1)\n",
    "\n",
    "#     # -----------------------------\n",
    "#     # Listes / tableaux\n",
    "#     # -----------------------------\n",
    "#     # features['has_list'] = int('[' in code and ']' in code)\n",
    "#     features['has_append'] = int('.append(' in code)\n",
    "\n",
    "#     return list(features.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a51_hWjqz_Ha"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_code_features(code: str):\n",
    "    code_l = code.lower()\n",
    "    features = {}\n",
    "\n",
    "    # =====================================================\n",
    "    # MATH / NUMBER THEORY\n",
    "    # =====================================================\n",
    "    features[\"has_mod\"] = int(\"%\" in code)\n",
    "    features[\"has_pow\"] = int(\"**\" in code or \"pow(\" in code)\n",
    "    features[\"has_gcd\"] = int(\"gcd\" in code_l)\n",
    "    features[\"has_lcm\"] = int(\"lcm\" in code_l)\n",
    "    features[\"has_prime\"] = int(\"prime\" in code_l)\n",
    "    features[\"has_factorial\"] = int(\"fact\" in code_l)\n",
    "    features[\"has_math_import\"] = int(\"import math\" in code_l)\n",
    "    features[\"has_bit_ops\"] = int(any(op in code for op in [\"<<\", \">>\", \"&\", \"|\", \"^\"]))\n",
    "\n",
    "    # =====================================================\n",
    "    # GRAPHS\n",
    "    # =====================================================\n",
    "    features[\"has_dfs\"] = int(\"dfs\" in code_l)\n",
    "    features[\"has_bfs\"] = int(\"bfs\" in code_l)\n",
    "    features[\"has_adj_list\"] = int(\"adj\" in code_l or \"neighbors\" in code_l)\n",
    "    features[\"has_edges\"] = int(\"edges\" in code_l)\n",
    "    features[\"has_queue\"] = int(\"deque\" in code_l or \"queue\" in code_l)\n",
    "    features[\"has_stack\"] = int(\"stack\" in code_l)\n",
    "    features[\"has_visited\"] = int(\"visited\" in code_l)\n",
    "\n",
    "    # =====================================================\n",
    "    # TREES\n",
    "    # =====================================================\n",
    "    features[\"has_tree\"] = int(\"tree\" in code_l)\n",
    "    features[\"has_node\"] = int(\"node\" in code_l)\n",
    "    features[\"has_left_right\"] = int(\"left\" in code_l and \"right\" in code_l)\n",
    "    features[\"has_recursion\"] = int(code.count(\"def\") > 1)\n",
    "    features[\"has_depth\"] = int(\"depth\" in code_l or \"height\" in code_l)\n",
    "\n",
    "    # =====================================================\n",
    "    # STRINGS\n",
    "    # =====================================================\n",
    "    features[\"has_string_literal\"] = int(bool(re.search(r\"['\\\"]\", code)))\n",
    "    features[\"has_split\"] = int(\".split(\" in code)\n",
    "    features[\"has_join\"] = int(\".join(\" in code)\n",
    "    features[\"has_replace\"] = int(\".replace(\" in code)\n",
    "    features[\"has_substring\"] = int(\"substr\" in code_l or \"substring\" in code_l)\n",
    "    features[\"has_ord_chr\"] = int(\"ord(\" in code or \"chr(\" in code)\n",
    "\n",
    "    # =====================================================\n",
    "    # PROBABILITIES\n",
    "    # =====================================================\n",
    "    features[\"has_probability\"] = int(\"prob\" in code_l or \"chance\" in code_l)\n",
    "    features[\"has_fraction\"] = int(\"fraction\" in code_l)\n",
    "    features[\"has_float_div\"] = int(\"/\" in code and \"//\" not in code)\n",
    "    features[\"has_expectation\"] = int(\"expect\" in code_l)\n",
    "\n",
    "    # =====================================================\n",
    "    # GAMES\n",
    "    # =====================================================\n",
    "    features[\"has_random\"] = int(\"random\" in code_l)\n",
    "    features[\"has_turn\"] = int(\"turn\" in code_l)\n",
    "    features[\"has_player\"] = int(\"player\" in code_l)\n",
    "    features[\"has_score\"] = int(\"score\" in code_l)\n",
    "    features[\"has_game_dp\"] = int(\"dp\" in code_l and (\"win\" in code_l or \"lose\" in code_l))\n",
    "\n",
    "    # =====================================================\n",
    "    # GEOMETRY\n",
    "    # =====================================================\n",
    "    features[\"has_point\"] = int(\"point\" in code_l)\n",
    "    features[\"has_distance\"] = int(\"dist\" in code_l)\n",
    "    features[\"has_angle\"] = int(\"angle\" in code_l)\n",
    "    features[\"has_cross_product\"] = int(\"cross\" in code_l)\n",
    "    features[\"has_dot_product\"] = int(\"dot\" in code_l)\n",
    "    features[\"has_hypot\"] = int(\"hypot\" in code_l)\n",
    "\n",
    "    return list(features.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XL06DKoCNEYh",
    "outputId": "bf988ae1-e7e4-4a5c-8dc6-540e841ec3aa"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vWQJEUqNrRcf"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df[\"tags\"])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Split train/val\n",
    "# -----------------------------\n",
    "X_train_text, X_val_text, y_train, y_val, train_idx, val_idx = train_test_split(\n",
    "    df[\"description_clean\"].tolist(),\n",
    "    y,\n",
    "    np.arange(len(df)),  # indices positionnels\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGcr00z-yo48",
    "outputId": "967be375-d6af-4187-a288-6d11f99525b6"
   },
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "X_val_tfidf   = vectorizer.transform(X_val_text)\n",
    "\n",
    "# Extraire features code\n",
    "X_train_code_features = np.array([extract_code_features(c) for c in df.iloc[train_idx][\"source_code\"]])\n",
    "X_val_code_features   = np.array([extract_code_features(c) for c in df.iloc[val_idx][\"source_code\"]])\n",
    "\n",
    "# Convertir en sparse matrix\n",
    "X_train_code_sparse = csr_matrix(X_train_code_features)\n",
    "X_val_code_sparse   = csr_matrix(X_val_code_features)\n",
    "\n",
    "# Combiner TF-IDF + code features\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_code_sparse])\n",
    "X_val_combined   = hstack([X_val_tfidf, X_val_code_sparse])\n",
    "\n",
    "print(\"‚úÖ Shape X_train_combined :\", X_train_combined.shape)\n",
    "print(\"‚úÖ Shape X_val_combined   :\", X_val_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0b0gVNLQUWV",
    "outputId": "d764f96f-4ffa-4817-8f08-78818d57acb4"
   },
   "outputs": [],
   "source": [
    "save_dir_3 = \"/content/drive/MyDrive/codeforces_classifier/code_source\"\n",
    "\n",
    "best_model_3, metrics_3 = run_ovr_linear_svc_pipeline(\n",
    "    X_train_combined,\n",
    "    y_train,\n",
    "    X_val_combined,\n",
    "    y_val,\n",
    "    best_params,\n",
    "    save_dir_3,\n",
    "    model_name=\"best_grid_search_ovr_linear_svc.joblib\",\n",
    "    mlb=mlb\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHKhLYkHpvzN"
   },
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "JGKcwGkoa5yF",
    "outputId": "790996b4-f41e-4b3a-be38-6d767fbb9128"
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MNHGXiE81AK"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df[\"tags\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCgcvw1gdkP1"
   },
   "outputs": [],
   "source": [
    "dtrain = pd.concat(\n",
    "    [\n",
    "        df[[\"description_clean\"]].reset_index(drop=True),\n",
    "        pd.DataFrame(\n",
    "            y,\n",
    "            columns=mlb.classes_\n",
    "        )\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "3zj7DeutkbDh",
    "outputId": "8f1f3201-e321-41b6-d498-84cc87a0cf83"
   },
   "outputs": [],
   "source": [
    "dtrain.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T10:37:15.603306Z",
     "iopub.status.busy": "2024-12-27T10:37:15.602856Z",
     "iopub.status.idle": "2024-12-27T10:37:15.609026Z",
     "shell.execute_reply": "2024-12-27T10:37:15.607932Z"
    },
    "id": "7e563526",
    "papermill": {
     "duration": 0.119812,
     "end_time": "2024-12-27T10:37:15.610967",
     "exception": false,
     "start_time": "2024-12-27T10:37:15.491155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X = dtrain['description_clean']\n",
    "y = dtrain[TARGET_TAGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_SNZkdmz9KND",
    "outputId": "98c04821-cc54-4390-8ddd-5b8d8ad9403d"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EL_JvDrxDdkR"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(dtrain['description_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AyNNIXlR9SxA",
    "outputId": "3294ae26-e1fd-4e7c-eec3-f227a04c0540"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qow9_wbeDdkS"
   },
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T10:39:03.316547Z",
     "iopub.status.busy": "2024-12-27T10:39:03.316016Z",
     "iopub.status.idle": "2024-12-27T10:39:03.322073Z",
     "shell.execute_reply": "2024-12-27T10:39:03.320666Z"
    },
    "id": "i8ExDcx9XlI0",
    "papermill": {
     "duration": 0.151382,
     "end_time": "2024-12-27T10:39:03.323876",
     "exception": false,
     "start_time": "2024-12-27T10:39:03.172494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def irpl(y : pd.DataFrame) -> pd.Series:\n",
    "    labels_count = y.sum(axis=0)\n",
    "    return labels_count.max() / labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-27T10:39:03.612017Z",
     "iopub.status.busy": "2024-12-27T10:39:03.611627Z",
     "iopub.status.idle": "2024-12-27T10:39:03.620094Z",
     "shell.execute_reply": "2024-12-27T10:39:03.618807Z"
    },
    "id": "raASEBQIXlI0",
    "outputId": "527e8ff6-ec6c-4256-f6d8-e1c32bb95bbd",
    "papermill": {
     "duration": 0.150456,
     "end_time": "2024-12-27T10:39:03.622029",
     "exception": false,
     "start_time": "2024-12-27T10:39:03.471573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "irpls = irpl(y_train)\n",
    "print(irpls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-27T10:39:04.175448Z",
     "iopub.status.busy": "2024-12-27T10:39:04.175015Z",
     "iopub.status.idle": "2024-12-27T10:39:04.182114Z",
     "shell.execute_reply": "2024-12-27T10:39:04.180514Z"
    },
    "id": "hRK6b5zeXlI0",
    "outputId": "5821f88a-6a0a-4e7e-82cb-669446349b5d",
    "papermill": {
     "duration": 0.142986,
     "end_time": "2024-12-27T10:39:04.184172",
     "exception": false,
     "start_time": "2024-12-27T10:39:04.041186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tail_labels = irpls.index[irpls > irpls.mean()]\n",
    "print(tail_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLortVwTdfaK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T10:39:04.714661Z",
     "iopub.status.busy": "2024-12-27T10:39:04.714172Z",
     "iopub.status.idle": "2024-12-27T10:39:04.737231Z",
     "shell.execute_reply": "2024-12-27T10:39:04.735888Z"
    },
    "id": "5lqbohdqXlI1",
    "papermill": {
     "duration": 0.160826,
     "end_time": "2024-12-27T10:39:04.739693",
     "exception": false,
     "start_time": "2024-12-27T10:39:04.578867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "class MLSMOTE:\n",
    "\n",
    "    def __init__(self,\n",
    "        n_neighbors : int = 5,\n",
    "        alpha_scale : float = 0.25,\n",
    "    ) -> None:\n",
    "\n",
    "        self.irpls = None\n",
    "        self.tail_labels = None\n",
    "        self.nn = None\n",
    "        self.labels_count = None\n",
    "\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha_scale = alpha_scale\n",
    "\n",
    "    def _irpl(self, y : pd.DataFrame) -> pd.Series:\n",
    "        labels_count = y.sum(axis=0)\n",
    "        return labels_count.max() / labels_count\n",
    "\n",
    "    def _tail_labels(self, y : pd.DataFrame) -> list[str]:\n",
    "        irpls = self._irpl(y)\n",
    "        return irpls.index[irpls > irpls.mean()].to_list()\n",
    "\n",
    "    def _labels_count(self) -> dict:\n",
    "\n",
    "        irpls = self.irpls\n",
    "        p = irpls / irpls.sum()\n",
    "        p = p ** -self.alpha_scale\n",
    "        p = p / p.sum()\n",
    "        p = p * len(y)\n",
    "        p = p.astype(int)\n",
    "        p = p[self.tail_labels].to_dict()\n",
    "\n",
    "        return p\n",
    "\n",
    "    def fit_resample(self, X : pd.DataFrame, y : pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "        ### Compute the IRPL for each label\n",
    "        irpls = self._irpl(y)\n",
    "        self.irpls = irpls\n",
    "\n",
    "        ### Get the tail labels\n",
    "        tail_labels = self._tail_labels(y)\n",
    "        self.tail_labels = tail_labels\n",
    "\n",
    "        ### Calculate the number of synthetic samples to generate for each tail label\n",
    "        labels_count = self._labels_count()\n",
    "        self.labels_count = labels_count\n",
    "\n",
    "        ### Restrict X and y to instances with tail labels\n",
    "        index = X.index[y[tail_labels].sum(axis=1) > 0]\n",
    "        subset_X = X.loc[index].reset_index(drop=True)\n",
    "        subset_y = y.loc[index].reset_index(drop=True)\n",
    "\n",
    "        ### Get the neighbors for each sample in the subset\n",
    "        nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn = nn.fit(X)\n",
    "        neighbors = nn.kneighbors(subset_X, return_distance=False)\n",
    "\n",
    "        ### Generate synthetic samples\n",
    "        X_synth = [X]\n",
    "        y_synth = [y]\n",
    "\n",
    "        for tail_label, count in labels_count.items():\n",
    "\n",
    "            # 1- Pick random reference samples\n",
    "            indices = np.arange(len(subset_X))\n",
    "            indices = indices[subset_y[tail_label] == 1]\n",
    "            reference_indices = np.random.choice(indices, count)\n",
    "\n",
    "            # 2- Pick random neighbors of the reference samples\n",
    "            random_neighbors = np.random.randint(1, self.n_neighbors, count)\n",
    "            random_neighbors = neighbors[reference_indices, random_neighbors]\n",
    "\n",
    "            # 3- Compute the difference between the reference samples and their neighbors\n",
    "            gap = subset_X.iloc[reference_indices].values - X.iloc[random_neighbors].values\n",
    "\n",
    "            # 4- Compute the synthetic samples features X\n",
    "            ratio = np.random.rand(count, 1)\n",
    "            X_new = subset_X.loc[reference_indices].values + ratio * gap\n",
    "            X_new = pd.DataFrame(X_new, columns=subset_X.columns)\n",
    "\n",
    "            # 5- Compute the synthetic samples labels y\n",
    "            y_new = y.values[neighbors[reference_indices,:].flatten()]\n",
    "            y_new = y_new.reshape(count, self.n_neighbors, subset_y.shape[1])\n",
    "            y_new = y_new.sum(axis=1) > 0\n",
    "            y_new = y_new.astype(int)\n",
    "            y_new = pd.DataFrame(y_new, columns=subset_y.columns)\n",
    "\n",
    "            # 6- Append the synthetic samples to the original dataset\n",
    "            X_synth.append(X_new)\n",
    "            y_synth.append(y_new)\n",
    "\n",
    "        X_synth = pd.concat(X_synth)\n",
    "        y_synth = pd.concat(y_synth)\n",
    "\n",
    "        return X_synth, y_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T10:39:14.901083Z",
     "iopub.status.busy": "2024-12-27T10:39:14.900726Z",
     "iopub.status.idle": "2024-12-27T10:39:15.098273Z",
     "shell.execute_reply": "2024-12-27T10:39:15.097030Z"
    },
    "id": "HAXiK3eai7CC",
    "papermill": {
     "duration": 0.331997,
     "end_time": "2024-12-27T10:39:15.100591",
     "exception": false,
     "start_time": "2024-12-27T10:39:14.768594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlsmote = MLSMOTE(alpha_scale=0.1)\n",
    "\n",
    "X_train_dense = X_train.toarray()  # Convert sparse to dense\n",
    "X_train_resampled, y_train_resampled = mlsmote.fit_resample(pd.DataFrame(X_train_dense, index=y_train.index), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q8piZ72FOTt"
   },
   "outputs": [],
   "source": [
    "X_val_dense = X_val.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-27T10:39:17.278059Z",
     "iopub.status.busy": "2024-12-27T10:39:17.277501Z",
     "iopub.status.idle": "2024-12-27T10:39:17.286367Z",
     "shell.execute_reply": "2024-12-27T10:39:17.284931Z"
    },
    "id": "370aadd4",
    "outputId": "90bb1323-8636-40eb-c653-ec54c2e379f5",
    "papermill": {
     "duration": 0.147485,
     "end_time": "2024-12-27T10:39:17.288261",
     "exception": false,
     "start_time": "2024-12-27T10:39:17.140776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "irpls = irpl(y_train_resampled)\n",
    "print(irpls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8dUbBdHi0YQ",
    "outputId": "c694113b-ec0b-4b24-ce7c-ea79af0dea7f"
   },
   "outputs": [],
   "source": [
    "save_dir_4 = \"/content/drive/MyDrive/codeforces_classifier/smote_model\"\n",
    "\n",
    "best_model_4, metrics_4 = run_ovr_linear_svc_pipeline(\n",
    "    X_train_resampled,\n",
    "    y_train_resampled,\n",
    "    X_val_dense,\n",
    "    y_val,\n",
    "    best_params,\n",
    "    save_dir_4,\n",
    "    model_name=\"ovr_linear_svc.joblib\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2bPSZkIf-yi"
   },
   "source": [
    "### <h2 id=\"7-comparaison-des-performances\">7. Comparaison des performances</h2>\n",
    "\n",
    "<p>\n",
    "Les mod√®les sont compar√©s selon plusieurs crit√®res :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>Micro F1-score (performance globale),</li>\n",
    "  <li>Macro F1-score (√©quit√© entre les tags),</li>\n",
    "  <li>Hamming Loss,</li>\n",
    "  <li>Performances par tag.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Cette analyse permet d‚Äôidentifier les forces et limites de chaque approche,\n",
    "ainsi que les tags les mieux pr√©dits.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpyaktpon_ff"
   },
   "outputs": [],
   "source": [
    "def train_evaluate_model(X_train, y_train, X_val, y_val, best_params, mlb=None):\n",
    "    \"\"\"\n",
    "    Entra√Æne OVR_LinearSVC et retourne les m√©triques et pr√©dictions.\n",
    "    \"\"\"\n",
    "    # Nettoyer params si GridSearch\n",
    "    clean_params = {k.replace(\"estimator__\", \"\"): v for k, v in best_params.items()}\n",
    "\n",
    "    model = OneVsRestClassifier(LinearSVC(class_weight=\"balanced\", **clean_params))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    metrics = evaluate_multilabel(y_val, y_pred, mlb)\n",
    "\n",
    "    return model, y_pred, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jl0tYWibwORi"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(df, text_column=\"description_clean\", code_column=None, tags_column=\"tags\",\n",
    "                    tfidf_max_features=5000, tfidf_ngram_range=(1,2), test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Pr√©pare les donn√©es pour le multi-label classification.\n",
    "    \"\"\"\n",
    "    # -----------------------------\n",
    "    # Binarisation des tags\n",
    "    # -----------------------------\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(df[tags_column])\n",
    "\n",
    "    # -----------------------------\n",
    "    # Split train/val\n",
    "    # -----------------------------\n",
    "    train_idx, val_idx = train_test_split(np.arange(len(df)), test_size=test_size, random_state=random_state)\n",
    "    X_train_text = [df.iloc[i][text_column] for i in train_idx]\n",
    "    X_val_text   = [df.iloc[i][text_column] for i in val_idx]\n",
    "    y_train = y[train_idx]\n",
    "    y_val   = y[val_idx]\n",
    "\n",
    "    # -----------------------------\n",
    "    # TF-IDF sur le texte\n",
    "    # -----------------------------\n",
    "    vectorizer = TfidfVectorizer(max_features=tfidf_max_features, ngram_range=tfidf_ngram_range)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "    X_val_tfidf   = vectorizer.transform(X_val_text)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Option : features du code source\n",
    "    # -----------------------------\n",
    "    if code_column is not None:\n",
    "        X_train_code_features = np.array([extract_code_features(df.iloc[i][code_column]) for i in train_idx])\n",
    "        X_val_code_features   = np.array([extract_code_features(df.iloc[i][code_column]) for i in val_idx])\n",
    "\n",
    "        X_train_code_sparse = csr_matrix(X_train_code_features)\n",
    "        X_val_code_sparse   = csr_matrix(X_val_code_features)\n",
    "\n",
    "        # Combiner TF-IDF + features code\n",
    "        X_train_combined = hstack([X_train_tfidf, X_train_code_sparse])\n",
    "        X_val_combined   = hstack([X_val_tfidf, X_val_code_sparse])\n",
    "    else:\n",
    "        X_train_combined = X_train_tfidf\n",
    "        X_val_combined   = X_val_tfidf\n",
    "\n",
    "    print(\"‚úÖ Shape X_train_tfidf :\", X_train_tfidf.shape)\n",
    "    print(\"‚úÖ Shape X_val_tfidf   :\", X_val_tfidf.shape)\n",
    "    print(\"‚úÖ Shape X_train_combined :\", X_train_combined.shape)\n",
    "    print(\"‚úÖ Shape X_val_combined   :\", X_val_combined.shape)\n",
    "\n",
    "    return X_train_tfidf, X_val_tfidf, X_train_combined, X_val_combined, y_train, y_val, mlb, train_idx, val_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CK3APGMQwfsC",
    "outputId": "e2e685eb-bdea-4c04-f19d-7cebb0b482bb"
   },
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es (TF-IDF seul + TF-IDF + features code)\n",
    "X_train_tfidf, X_val_tfidf, X_train_combined, X_val_combined, y_train, y_val, mlb, train_idx, val_idx = prepare_dataset(\n",
    "    df,\n",
    "    text_column=\"description_clean\",\n",
    "    code_column=\"source_code\",  # None si pas de features code\n",
    "    tags_column=\"tags\",\n",
    "    tfidf_max_features=5000,\n",
    "    tfidf_ngram_range=(1,2),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isSBanYOwrLU"
   },
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y_train, columns=mlb.classes_)\n",
    "\n",
    "mlsmote = MLSMOTE(alpha_scale=0.1)\n",
    "\n",
    "# Convertir X_train en dense si n√©cessaire\n",
    "X_train_dense = X_train_tfidf.toarray()  # TF-IDF seul\n",
    "\n",
    "# Resample\n",
    "X_train_resampled, y_train_resampled = mlsmote.fit_resample(\n",
    "    pd.DataFrame(X_train_dense),\n",
    "    y_df  # DataFrame avec colonnes = noms des tags\n",
    ")\n",
    "\n",
    "# Conversion pour validation\n",
    "X_val_dense = X_val_tfidf.toarray() if not isinstance(X_val_tfidf, np.ndarray) else X_val_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFOfBxoAoByV",
    "outputId": "226e7c0d-b889-4476-e3aa-a44748471928"
   },
   "outputs": [],
   "source": [
    "results_comparison = []\n",
    "\n",
    "# Mod√®le avec seulement les descriptions\n",
    "model_desc, y_pred_desc, metrics_desc = train_evaluate_model(\n",
    "    X_train_tfidf, y_train, X_val_tfidf, y_val, best_params, mlb\n",
    ")\n",
    "results_comparison.append({\"approach\": \"Descriptions only\", **metrics_desc})\n",
    "\n",
    "# Mod√®le avec description + features du code source\n",
    "model_combined, y_pred_combined, metrics_combined = train_evaluate_model(\n",
    "    X_train_combined, y_train, X_val_combined, y_val, best_params, mlb\n",
    ")\n",
    "results_comparison.append({\"approach\": \"Descriptions + code features\", **metrics_combined})\n",
    "\n",
    "# Mod√®le avec SMOTE / resampling\n",
    "model_smote, y_pred_smote, metrics_smote = train_evaluate_model(\n",
    "    X_train_resampled, y_train_resampled, X_val_dense, y_val, best_params, mlb\n",
    ")\n",
    "results_comparison.append({\"approach\": \"Resampled (SMOTE)\", **metrics_smote})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "ptYJLxGTom4b",
    "outputId": "c0fd66f0-7452-496a-ba82-8c4a4ce4b43b"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_comparison).set_index(\"approach\")\n",
    "\n",
    "# Trier par f1_macro d√©croissant\n",
    "results_df = results_df.sort_values(by=\"f1_macro\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Comparaison des approches tri√©e par Macro F1 ===\")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8kBvVgVopOx"
   },
   "outputs": [],
   "source": [
    "def plot_results(results: pd.DataFrame) -> None:\n",
    "    n_metrics = len(results.columns)\n",
    "    n_cols = 2\n",
    "    n_rows = int(np.ceil(n_metrics / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, metric in enumerate(results.columns):\n",
    "        sns.barplot(data=results, x=results.index, y=metric, ax=axes[i])\n",
    "        axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
    "        axes[i].set_title(metric)\n",
    "\n",
    "    # cacher les axes inutilis√©s\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H4IqLPpupMrd",
    "outputId": "3a717fec-936f-461b-8690-5bc93a065636"
   },
   "outputs": [],
   "source": [
    "# Visualisation simple\n",
    "plot_results(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhaHD7HFpage"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(y_true: pd.DataFrame, y_pred: pd.DataFrame):\n",
    "    n_labels = len(y_true.columns)\n",
    "    n_cols = 4  # nombre de colonnes par ligne\n",
    "    n_rows = int(np.ceil(n_labels / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    axes = axes.flatten()  # pour it√©rer facilement\n",
    "\n",
    "    for i, label in enumerate(y_true.columns):\n",
    "        cm = confusion_matrix(y_true[label], y_pred[label])\n",
    "        cm = cm.astype(float) / cm.sum(axis=1)[:, None]  # normalisation\n",
    "        sns.heatmap(cm, ax=axes[i], annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "        axes[i].set_title(f\"{label}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "32GFeqe8pUqX",
    "outputId": "583e7eed-59e2-4288-9031-6cdb8fcb1c9f"
   },
   "outputs": [],
   "source": [
    "best_approach = results_df[\"f1_macro\"].idxmax()\n",
    "print(f\"\\nüéØ Meilleur mod√®le : {best_approach}\")\n",
    "\n",
    "if best_approach == \"Descriptions only\":\n",
    "    y_pred_best = y_pred_desc\n",
    "elif best_approach == \"Descriptions + code features\":\n",
    "    y_pred_best = y_pred_combined\n",
    "else:\n",
    "    y_pred_best = y_pred_smote\n",
    "\n",
    "# Conversion en DataFrame avec noms des tags\n",
    "y_val_df = pd.DataFrame(y_val, columns=mlb.classes_)\n",
    "\n",
    "# Plot confusion matrices pour le meilleur mod√®le\n",
    "plot_confusion_matrices(y_val_df, pd.DataFrame(y_pred_best, columns=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2q4ThUaOrQav"
   },
   "outputs": [],
   "source": [
    "def plot_results(results: pd.DataFrame) -> None:\n",
    "    n_metrics = len(results.columns)\n",
    "    n_cols = 2\n",
    "    n_rows = int(np.ceil(n_metrics / n_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, metric in enumerate(results.columns):\n",
    "        sns.barplot(data=results, x=results.index, y=metric, ax=axes[i])\n",
    "        axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
    "        axes[i].set_title(metric)\n",
    "\n",
    "    # cacher les axes inutilis√©s\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxDIZzHNssA-"
   },
   "outputs": [],
   "source": [
    "def evaluate_label_wise(y_true: pd.DataFrame, y_pred: pd.DataFrame, metrics: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    √âvalue chaque label/tag s√©par√©ment selon les m√©triques fournies.\n",
    "\n",
    "    Arguments :\n",
    "        y_true : DataFrame avec les vrais labels\n",
    "        y_pred : DataFrame avec les pr√©dictions\n",
    "        metrics : dict {nom_m√©trique: fonction} pour calculer les m√©triques\n",
    "\n",
    "    Retourne :\n",
    "        DataFrame avec les m√©triques pour chaque label et une ligne 'Mean'\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for label in y_true.columns:\n",
    "        row = {}\n",
    "        for metric_name, metric_func in metrics.items():\n",
    "            row[metric_name] = metric_func(y_true[label], y_pred[label])\n",
    "        results.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(results, index=y_true.columns)\n",
    "    results_df.loc['Mean'] = results_df.mean(axis=0)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjVeExYlsuza"
   },
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    \"F1\": lambda y_t, y_p: f1_score(y_t, y_p, zero_division=0),\n",
    "    \"Precision\": lambda y_t, y_p: precision_score(y_t, y_p, zero_division=0),\n",
    "    \"Recall\": lambda y_t, y_p: recall_score(y_t, y_p, zero_division=0),\n",
    "    \"Accuracy\": lambda y_t, y_p: accuracy_score(y_t, y_p)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PeCG7EntTnO"
   },
   "outputs": [],
   "source": [
    "y_pred_best_df = pd.DataFrame(y_pred_best, columns= mlb.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "BT70PpGNr5k-",
    "outputId": "3c54addd-7d64-4d25-e6b0-f72ef611d11e"
   },
   "outputs": [],
   "source": [
    "# Calcul m√©triques par label\n",
    "moc_results = evaluate_label_wise(y_val_df, y_pred_best_df, metrics_dict)\n",
    "\n",
    "print(f\"\\nüéØ M√©triques d√©taill√©es par label pour le meilleur mod√®le ({best_approach}) :\")\n",
    "display(moc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nlwhZD42tiDZ",
    "outputId": "8385375b-c657-4a12-e609-0b2686dafce9"
   },
   "outputs": [],
   "source": [
    "plot_results(moc_results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f312db1770241a198290debe179d09d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27dad44bc66b4b31afa9545098c95e36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b88b7a2b7ee4c729639afc032787e26",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6be54fe376784722a6a61384caf6d839",
      "value": "100%"
     }
    },
    "3ac3432d6c2143318ad7683c27b4897e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9123cdba051645a8932450bcf2731624",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f7686fca67c748ea9613bff24cde019b",
      "value": "‚Äá2678/2678‚Äá[00:07&lt;00:00,‚Äá211.56it/s]"
     }
    },
    "6a966cf1d88e4a7d9298bc1e1cbe9e2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdae4800015a42e9a8342aa80c31ec32",
      "max": 2678,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f312db1770241a198290debe179d09d",
      "value": 2678
     }
    },
    "6be54fe376784722a6a61384caf6d839": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b88b7a2b7ee4c729639afc032787e26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9123cdba051645a8932450bcf2731624": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d755dadd12ca42e49cc3da24f09cb9e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27dad44bc66b4b31afa9545098c95e36",
       "IPY_MODEL_6a966cf1d88e4a7d9298bc1e1cbe9e2a",
       "IPY_MODEL_3ac3432d6c2143318ad7683c27b4897e"
      ],
      "layout": "IPY_MODEL_d9b1caa8b14b4f6db1d602525082aadd"
     }
    },
    "d9b1caa8b14b4f6db1d602525082aadd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7686fca67c748ea9613bff24cde019b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdae4800015a42e9a8342aa80c31ec32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
